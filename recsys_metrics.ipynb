{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from src.data import get_dataset\n",
    "from dt4rec_utils import make_rsa\n",
    "from cql_dqn import DQNCQL\n",
    "from metrics import Evaluator\n",
    "\n",
    "DEVICE = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 115 invalid observations.\n",
      "Filtered 11 invalid observations.\n",
      "Filtered 4 invalid observations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "userid\n",
       "1       [2935, 1160, 1552, 941, 2117, 1633, 3136, 2566...\n",
       "2       [1090, 1102, 1109, 2479, 1183, 2702, 1117, 108...\n",
       "3       [573, 2618, 3260, 1762, 1307, 1755, 1156, 1259...\n",
       "4       [1102, 1008, 3194, 463, 3253, 253, 1088, 1090,...\n",
       "5       [2479, 832, 843, 1140, 346, 2618, 1033, 1981, ...\n",
       "                              ...                        \n",
       "5998    [1268, 1269, 1270, 3136, 3300, 3313, 3034, 323...\n",
       "6001    [3464, 3207, 1562, 1544, 2635, 1139, 1242, 889...\n",
       "6002    [1736, 440, 1740, 2049, 2849, 265, 961, 2898, ...\n",
       "6016    [3570, 3463, 3507, 1344, 2880, 3601, 27, 2466,...\n",
       "6040    [2932, 2348, 1104, 3092, 3148, 1148, 1160, 186...\n",
       "Name: itemid, Length: 1739, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, data_description, _, testset, _, holdout = get_dataset(\n",
    "    validation_size=1024, test_size=5000, data_path='./data/ml-1m.zip', splitting='temporal_full', q=0.8)\n",
    "\n",
    "inference_sequences = testset.groupby('userid', sort=False)['itemid'].apply(list)\n",
    "inference_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def create_sasrec_predictions(\n",
    "    sequences,\n",
    "    sasrec_path: str,\n",
    "    device: torch.device\n",
    "):\n",
    "    sasrec = torch.load(sasrec_path).to(device)\n",
    "    sasrec.eval()\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for u, seq in tqdm(sequences.items(), total=len(sequences)):\n",
    "        s = torch.LongTensor(seq).to(device)\n",
    "        logits = sasrec.score_with_state(s)[0].flatten().detach().cpu().numpy()[:-1]\n",
    "        scores.append(logits)\n",
    "\n",
    "    return np.stack(scores)\n",
    "\n",
    "@torch.no_grad()\n",
    "def create_cqlsasrec_predictions(\n",
    "    sequences,\n",
    "    cql_path: str,\n",
    "    device: torch.device\n",
    "):\n",
    "    trainer = torch.load(cql_path)\n",
    "    trainer.q_1 = trainer.q_1.to(device)\n",
    "    trainer.q_2 = trainer.q_2.to(device)\n",
    "    trainer.body = trainer.body.to(device)\n",
    "    trainer.q_1.eval()\n",
    "    trainer.q_2.eval()\n",
    "    trainer.body.eval()\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for u, seq in tqdm(sequences.items(), total=len(sequences)):\n",
    "        s = torch.LongTensor(seq).to(device)\n",
    "        body_out = trainer.body.score_with_state(s)[-1]\n",
    "        body_out = body_out.reshape(-1, body_out.shape[-1])\n",
    "        out = (trainer.q_1(body_out) + trainer.q_2(body_out)) / 2.0\n",
    "        scores.append(out.flatten()[:-1].cpu().numpy())\n",
    "\n",
    "    return np.stack(scores)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def create_dt4rec_predictions(\n",
    "    sequences,\n",
    "    dt4rec_path: str,\n",
    "    device: torch.device\n",
    "):\n",
    "    dt4rec = torch.load(dt4rec_path).to(device)\n",
    "    dt4rec.eval()\n",
    "\n",
    "    item_num = dt4rec.config.vocab_size\n",
    "    seq_len = 100\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for u, seq in tqdm(sequences.items(), total=len(sequences)):\n",
    "        s = torch.LongTensor(seq).to(device)\n",
    "        s = F.pad(s, (seq_len - 1 - len(s), 0), value=item_num)\n",
    "        rsa = {\n",
    "            key: value[None, ...].to(device)\n",
    "            for key, value in make_rsa(s, 3, item_num).items()\n",
    "        }\n",
    "        state = dt4rec(**rsa)\n",
    "        # [:-1] to fix a bug\n",
    "        scores.append(state[:, -1, :].flatten()[:-1].cpu().numpy())\n",
    "\n",
    "    return np.stack(scores)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def create_ssknn_predictions(\n",
    "    sequences,\n",
    "    ssknn_path: str\n",
    "):\n",
    "    ssknn = torch.load(ssknn_path)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for u, seq in tqdm(sequences.items(), total=len(sequences)):\n",
    "        s = seq\n",
    "        d = pd.DataFrame({'itemid' : s, 'timestamp' : np.arange(len(s))})\n",
    "        d['userid'] = u\n",
    "        sc = ssknn.recommend(d, data_description).ravel()\n",
    "        # sc[seq[-1]] = 0.0\n",
    "        scores.append(sc)\n",
    "\n",
    "    return np.stack(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'sasrec_2' : './models/sasrec_2.pt',\n",
    "    'sasrec_3' : './models/sasrec_3.pt',\n",
    "    'sasrec_4' : './models/sasrec_4.pt',\n",
    "    'dt4rec' : './models/dt4rec.pt',\n",
    "    'cql_sasrec' : './models/cql_sasrec.pt',\n",
    "    'ssknn' : './models/ssknn.pt',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1739/1739 [00:02<00:00, 737.91it/s]\n",
      "100%|██████████| 1739/1739 [00:02<00:00, 836.39it/s]\n",
      "100%|██████████| 1739/1739 [00:02<00:00, 822.75it/s]\n",
      "100%|██████████| 1739/1739 [00:03<00:00, 578.09it/s]\n",
      "100%|██████████| 1739/1739 [00:02<00:00, 742.64it/s]\n",
      "100%|██████████| 1739/1739 [00:15<00:00, 113.70it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(top_k=[10])\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for k,v in models.items():\n",
    "    if k in ['sasrec_2', 'sasrec_3', 'sasrec_4']:\n",
    "        scores[k] = create_sasrec_predictions(inference_sequences, v, DEVICE)\n",
    "    elif k == 'dt4rec':\n",
    "        scores[k] = create_dt4rec_predictions(inference_sequences, v, DEVICE)\n",
    "    elif k == 'cql_sasrec':\n",
    "        scores[k] = create_cqlsasrec_predictions(inference_sequences, v, DEVICE)\n",
    "    elif k == 'ssknn':\n",
    "        scores[k] = create_ssknn_predictions(inference_sequences, v)\n",
    "\n",
    "metrics_all = {}\n",
    "for k, v in scores.items():\n",
    "    s = evaluator.downvote_seen_items(v, testset)\n",
    "    recs = evaluator.topk_recommendations(s)\n",
    "    metrics = evaluator.compute_metrics(holdout, recs)\n",
    "    metrics_all[k] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcg@10</th>\n",
       "      <th>hr@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sasrec_2</th>\n",
       "      <td>0.094667</td>\n",
       "      <td>0.182864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cql_sasrec</th>\n",
       "      <td>0.090978</td>\n",
       "      <td>0.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sasrec_3</th>\n",
       "      <td>0.070142</td>\n",
       "      <td>0.133985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssknn</th>\n",
       "      <td>0.062707</td>\n",
       "      <td>0.123059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt4rec</th>\n",
       "      <td>0.034410</td>\n",
       "      <td>0.063255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sasrec_4</th>\n",
       "      <td>0.017741</td>\n",
       "      <td>0.037378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ndcg@10     hr@10\n",
       "sasrec_2    0.094667  0.182864\n",
       "cql_sasrec  0.090978  0.170213\n",
       "sasrec_3    0.070142  0.133985\n",
       "ssknn       0.062707  0.123059\n",
       "dt4rec      0.034410  0.063255\n",
       "sasrec_4    0.017741  0.037378"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics_all).T.sort_values(by='ndcg@10', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
